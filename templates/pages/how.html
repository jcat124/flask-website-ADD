<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="../../static/how.css">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" type="image/jpg" href="{{ ADDPlus_icon }}"/>
    <title>How</title>
</head>
<body>
    <nav>
        <img src="{{ ADDPlus_icon }}" alt="drowsy_icon">
        <p><a href="/"><strong>Anti-Drowsy Driving Plus (ADD+)</strong></a></p>
        
        <ul>
            <li><strong><a href="/">Home ▼</a></strong>
            <ul>
                    <li><strong><a href="/#download">Download</a></strong></li>
                    <li><strong><a href="/#instructions">Instructions</a></strong></li>
                    <li><strong><a href="/#troubleshoot">Troubleshoot</a></strong></li>                
            </ul>
            </li>
            <li><strong><a href="/why">Why ▼</a></strong>
            <ul>
                <li><strong><a href="/why">Why</a></strong></li>
                <li><strong><a href="/why#references">References</a></strong></li>
            </ul>
            </li>
            <li><strong><a href="/how">How</a></strong></li>
            <li><strong><a href="/about">About Me</a></strong></li>
        </ul>
    </nav>

    <h4>

    </h4>
    <h1>
        <span><b>HOW</b></span>
    </h1>
    <div class="how_img">
        <img src="{{ how_image }}" alt="how_image">
    </div>

    <div class="how_body">
        <div class="how_par">
            <p>
                I started this project around a year ago. Without any prior knowledge of coding/ programming,
                I started learning from scratch. I taught myself from online research and tutorials,
                and I also took a couple of free online Harvard University courses during my summer holidays.
                For many months, in the beginning, I faced dozens of failed attempts only—I tried arduino,
                started learning Javascript and react-native, tried color detection etc., but nothing was working at all.
                But, I kept working hard and stayed persistent.
                It took me 5-6 months to see a glimpse of my first success.
            </p>    
        </div>

        <div class="how_par">
            <p>
                For my project:
            </p>
            <div class="how_list">
                <ol>
                    <li>
                        <p>
                            I created a <b><u>Desktop App:</u> Anti-Drowsy Driving Plus (ADD+)</b>
                        </p>

                        <p>
                            I taught myself Python programming language and learned to make my first app using Python.
                        </p>
                    </li>
                    <li>
                        <p>
                            I also created a <b><u>Website:</u></b> <a href="https://anti-drowsy-driving-plus.herokuapp.com/" target="_blank">https://anti-drowsy-driving-plus.herokuapp.com/</a>
                        </p>
                        <p>
                            I self-learned HTML and CSS programming languages to make my first website
                            so that people can download and use my app for free.
                        </p>
                    </li>
                </ol>
            </div>
           
        </div>

        <div class="how_par">
            <p>
                I used the following Python libraries for my project:
            </p>
            <div class="how_list">
                <ul>
                    <li>
                        OpenCV: To access and use the webcam and edit it by drawing green lines around the eyes and mouth,
                        and displaying text alerts on the screen.
                    </li>
                    <li>
                        Dlib: Used it to detect facial landmarks e.g. eyes, nose, mouth etc.
                    </li>
                    <li>
                        From scipy.spatial: I used ‘distance’ that is used in the EAR and MAR algorithm.
                    </li>
                    <li>
                        Face-utils: Used it to retrieve the indexes for both eyes and mouth.
                    </li>
                    <li>
                        Imutils: An add-on for cv2 that I used to resize and crop webcam videos.
                    </li>
                    <li>
                        Winsound: To play alarm sound and beeps from the computer speaker when the driver is drowsy.
                    </li>
                    <li>
                        Pyttxs3: To use the computer speaker to talk to the user (text-to-speech).
                        The speech was adjusted for speed, volume, and male/female voice.
                    </li>
                    <li>
                        Speech_recognition: To access the microphone to take user’s verbal/audio input,
                        and convert it to text (speech-to-text).
                    </li>
                    <li>
                        Random: Used it to generate
                        a random integer to fetch random Q/A and jokes from 250 lines
                        .txt files each for Q/A and jokes.
                    </li>
                    <li>
                        Time: Used it to give little pauses in my code.
                    </li>
                    <li>
                        PyInstaller: To convert .py file to .exe file
                    </li>
                </ul>
            </div>
        </div>

        <div class="how_img">
            <img src="{{ flowchart1 }}" alt="A flowchart to explain my program">
        </div>
        
        <div class="how_par">
            <p>
                There are two Major Versions of my app based on user/ driver’s needs and preferences:
            </p>
            <div class="how_list">
                <ol>
                    <li>
                        <p>
                            <u>Drowsiness Detection:</u> When the driver is drowsy—either shutting eyes and/or yawning,
                            my app sounds an alarm right away to alert the driver.
                        </p>
                    </li>
                    <li>
                        <p>
                            <u>Interaction:</u> I invented a <b><u>Virtual Friend Speech-Robot</u></b> that can talk to you
                            when you feel drowsy,
                            to help you stay awake because data shows that most road accidents occur
                            when the driver is alone in their vehicle,
                            and on quiet rural roads and highways.[16,18] 
                        </p>
                    </li>
                </ol>
            </div>
        </div>

        <div class="how_title">
            <h2>
                1). Drowsiness Detection:
            </h2>
        </div>

        <div class="how_par">
            <p>
                To do things fast (with speed), my code converts webcam video to grayscale because we don’t need color, we only need to track the eyes’ and mouth’s movements. My code then detects face and puts facial landmarks (mouth, nose, eyes, lips) on the user's face, then the facial landmarks (eyes and mouth) are fed in the algorithm. My program also draws green lines around the eyes and mouth to let the user know if they are properly detected, so the user can understand how it works and feel more protected instead of knowing nothing about it.
            </p>
        </div>

        <div class="how_par">
            <p>
                My code simultaneously monitors the driver’s eyes and mouth,
                and detects drowsiness by detecting shutting eyes and/or yawning, and alerts the driver
                right away with an alarm sound. I used the Eye Aspect Ratio (EAR) and Mouth Aspect Ratio (MAR) algorithm [21-23]
                which gives you real-time numbers that change every millisecond, but then I code it to detect drowsiness.
                As shown below, the EAR and  MAR algorithm mark 6 points (P₁ to P₆) around the eyes and mouth, and according
                to the following formula, it calculates the driver’s real-time ‘EAR and MAR values’ every millisecond
                continuously. These values range from around 0.05 to 0.25 for EAR and around 0.4 to 0.8 for MAR, and it changes
                according to your eyelids and mouth opening or closing. Obviously, EAR (open eye) > EAR (close eye), and MAR
                (open mouth) > MAR (close mouth). When EAR > 0.2, it means that the eyes are open and the driver is not drowsy;
                and when EAR < 0.1, the eyes are close, and it may be due to blinking or drowsiness depending on how long
                the eyes are close for—if it’s just for a fraction of a second, then it’s blinking, but if it’s closed for
                longer, that is around 1-3 seconds, then it’s drowsiness. But, there is no timer running alongside, so to
                know for how long the eyes are closed for, I declared a ‘counter’ variable. The initial ‘counter’ value was 0,
                and each time a close-eye is detected, it increments the ‘counter’ by 1, and when the ‘counter’ value reaches 20
                (that is the eyes are closed for 1-3 seconds), it sends out an alert alarm to wake up the driver. In my program,
                after several rounds of intensive testing, I set a threshold for EAR = 0.2 and a threshold for MAR = 0.9, to
                accurately detect the drowsiness right away. If EAR < 0.2 threshold continuously for 20 consecutive picture frames,
                and/or if MAR > 0.9 threshold, then my app sounds an alarm right away to alert the driver.
                And then the ‘counter’ value is reset back to 0 each time.
                And the whole code runs in infinite loops until the user closes the app by pressing “e” (to exit the app).
            </p>
        </div>

        <div class="how_img">
            <img src="{{ algorithm_image }}" alt="A image telling you about the EAR algorithm">
        </div>

        <div class="how_img">
            <img src="{{ face_index }}" alt="A image telling you about both algorithm">
        </div>

        <div class="how_title">
            <h2>
                2). Interaction: Virtual Friend Speech-Robot
            </h2>
        </div>

        <div class="how_par">
            <p>
                I created a Virtual Friend Speech-Robot with speech_recognition and pyttsx3. I used speech_recognition to convert what the user is saying to text (speech-to-text), and pyttsx3 to use the computer speaker to respond and ask (text-to-speech). After sounding an alert alarm when the driver is drowsy, the Virtual Friend Speech-Robot—that I invented—suggests the driver to take a break, have some hot tea/ coffee etc., and also gives an option if the driver wants to talk to the Virtual Friend Speech-Robot to help stay awake. If the driver doesn’t want to interact, it goes back to drowsiness detection; but if the driver wants to interact, my Virtual Friend Speech-Robot asks 10 question-answers (Q-A) and jokes one-by-one from the set of 500 fun, interesting question-answers and jokes that I compiled from online [24-35], and let the user know if they answered right or wrong. After that, my Virtual Friend Speech-Robot again asks if the driver wants to interact more—it’s in a loop.
            </p>
            
        </div>

        <div class="how_par">
            <p>
                The Q-A and jokes are delivered randomly so that each has an equal chance of occurring even when the trip is short. Because, when the driver’s trip is short, all 500 Q-A and jokes can’t be delivered; and in that case, if the Q-A and jokes were delivered in ascending order from 1 to 500, the driver would only get to listen to the first few Q-A and jokes every time and can’t get to listen to the bottom set of Q-A and jokes, so I write the code so that all Q-A and jokes are delivered randomly. 
            </p>
        </div>

        <div class="how_par">
            <p>
                The driver interacts by answering fun True or False (T/F) questions. Instead of the multiple-choice or short-answer questions that require more focus and concentration, I choose very short T/F questions because it’s very simple and fun and helps the driver stay awake and doesn’t provoke distracted driving.
            </p>
        </div>

        <div class="how_par">
            <p>
                The Virtual Friend Speech-Robot that I invented, will help drivers stay more alert because 50% of drowsy driving accidents occur on certain, quiet rural roads and highways [18], mostly among drivers who are alone in their vehicles.[16] Being alone and not hearing any noises for a long time can make you feel drowsy. Driving alone or with sleeping passengers can dramatically increase the risk of an accident. So, my Virtual Friend Speech-Robot invention will save lives—it will help drivers stay awake by interacting with them and giving them company.
            </p>
        </div>

        <div class="how_title">
            <h2>
                Some CHALLENGES I Faced:
            </h2>
        </div>


        <div class="how_subhead_challenge">
            <h3>
                <b><u>Coding:</u></b>
            </h3>
        </div>

        <div class="how_par_bold_challenge">
            <p>
                <b>PyAudio:</b>
            </p>
        </div>

        <div class="how_par_challenge">
            <p>
                I had problems installing the PyAudio library with pip (the default python package installer). After researching, I found that this problem can be overcome by installing the python binary packages according to your python version. After installing, you can find the path to the binary package and install PyAudio using pip.
            </p>
        </div>


        <div class="how_par_bold_challenge">
            <p>
                <b>Speech_Recognition.UnknownValueError():</b>
            </p>
        </div>

        <div class="how_par_challenge">
            <p>
                I had errors with the speech_recognition library. When my app asks the user to say ‘yes’ or ‘no’, there could be many different possibilities in which the user could respond. The user may say ‘yes’, or ‘no’, or both ‘yes’ and ‘no’ simultaneously, or can be just quiet, or say something else, or the user may have different pronunciation/ accent, or there may be many different talking voices. So, instead of saying ‘yes’ or ‘no’ as asked, if the user responds in any other ways—it breaks the program. First, I tried to fix this by adding a ‘try’ and ‘except’. I added a try block and then put my whole code underneath it and then added an ‘except speech_recognition.UnknowValueError’. Underneath that exception, I added a 'pass' which basically just moves onto the next code—that is the drowsiness detector code. Finally, I changed the above code by saying ‘except Exception’ and ‘pass’, so then if there are any errors, it goes back to drowsiness detection.
            </p>
        </div>


        <div class="how_par_bold_challenge">
            <p>
                <b>Random Q/A and Jokes:</b>
            </p>
        </div>

        <div class="how_par_challenge">
            <p>
                I had a hard time fetching random questions with their corresponding answers because they were generated differently. I fixed this problem by generating a random integer; and after reading the questions’, answers’, and jokes’ .txt file, I put them in strings in an array. After that, I store the randomly generated integer in a variable and assign it to the questions array and answers array, so they are the same string, that is, the same line.
            </p>
        </div>

        <div class="how_subhead_challenge">
            <h3>
                <u>Making App Public:</u>
            </h3>
        </div>

        <div class="how_par_bold_challenge">
            <p>
                <b>
                    Pyinstaller (to make .exe file):
                </b>
            </p>
        </div>

        <div class="how_par_challenge">
            <p>
                It was hard making the app. I had to convert it from .py to .exe file. The biggest challenge was that I couldn’t install PyAudio with the .exe file. I also couldn't install it on my local system, which I later resolved. I tried fixing it with hidden-import and installing PyAudio, but it didn’t work. To fix the problem, I finally upgraded Pyinstaller to the latest version and typed the following command: 
            </p>
        </div>

        <div class="how_img">
            <img src="{{ pyinstaller_command }}" alt="A image telling you about pyinstaller command to turn .py to .exe">
        </div>

        <div class="how_par_bold">
            <p>
                <b>
                    Inno Setup and Bitbucket (to make setup wizard):
                </b>
            </p>
        </div>

        <div class="how_par_challenge">
            <p>
                To make the setup wizard, I first used NSIS but it didn’t have the functionality I needed. After more research, I came across Inno Setup and made my own Installer for my .exe file. The whole point of the setup wizard was to make it downloadable on other computers for free public use. The problem was that the setup wizard was 119 MB and Github (the place where I stored my setup wizard) only allows files smaller than 25 MB. So, I used Git Lfs which allows you to store bigger files on Github. But still, the problem was that after I change some code in my .py file, I have to make the .exe file all over again and then feed that .exe file to the setup installer, compile it, and then use Git Lfs to store it on Github. But, I can’t store it on Github anymore because I used all the bandwidth that my account provides to store files larger than 25 MB. So, I started looking for alternatives to Github, and found Bitbucket. On Bitbucket, using Git Lfs, I could put as many large files as I want without having to worry about bandwidth. After that, I just pasted the URLs of my stored files onto my website so that other people can download my app.
            </p>
        </div>

    </div>
        
</body>
</html>
